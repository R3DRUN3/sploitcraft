{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","authorship_tag":"ABX9TyOqyTtY5V8JG0zNNEJ7dOle"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","widgets":{"application/vnd.jupyter.widget-state+json":{"23a9d9c75d01413abae3764924051cfc":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_7e5391204e0d4c028e99ebfe6096d9ad","IPY_MODEL_b4152986ef394a4faf1bde2a30a7a3a6","IPY_MODEL_9f196a10cc9649319dcab8f448343086"],"layout":"IPY_MODEL_abfffcb57a8f4709a20eaf9e91f6d3c5"}},"7e5391204e0d4c028e99ebfe6096d9ad":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_ea5ba01d788e49a0931681611e77622c","placeholder":"​","style":"IPY_MODEL_9221a33179cc478d9b7f7f481b77d47c","value":"Map: 100%"}},"b4152986ef394a4faf1bde2a30a7a3a6":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_6930ed41b4b040ee953c2fe6b3250e41","max":2000,"min":0,"orientation":"horizontal","style":"IPY_MODEL_53192330650e4be1be8bef558172b5a7","value":2000}},"9f196a10cc9649319dcab8f448343086":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_7ef8a5cad36344459bfbc766361fe24f","placeholder":"​","style":"IPY_MODEL_a0fa6db81b0c48c6ab19f56d1414bdc5","value":" 2000/2000 [00:00&lt;00:00, 4252.78 examples/s]"}},"abfffcb57a8f4709a20eaf9e91f6d3c5":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ea5ba01d788e49a0931681611e77622c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9221a33179cc478d9b7f7f481b77d47c":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"6930ed41b4b040ee953c2fe6b3250e41":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"53192330650e4be1be8bef558172b5a7":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"7ef8a5cad36344459bfbc766361fe24f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a0fa6db81b0c48c6ab19f56d1414bdc5":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"cells":[{"cell_type":"markdown","source":["OWASP LLM TOP 10: LLM03 - TRAINING DATASET POISONING"],"metadata":{"id":"osZnsoQ4gLQV"}},{"cell_type":"code","execution_count":5,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000,"referenced_widgets":["23a9d9c75d01413abae3764924051cfc","7e5391204e0d4c028e99ebfe6096d9ad","b4152986ef394a4faf1bde2a30a7a3a6","9f196a10cc9649319dcab8f448343086","abfffcb57a8f4709a20eaf9e91f6d3c5","ea5ba01d788e49a0931681611e77622c","9221a33179cc478d9b7f7f481b77d47c","6930ed41b4b040ee953c2fe6b3250e41","53192330650e4be1be8bef558172b5a7","7ef8a5cad36344459bfbc766361fe24f","a0fa6db81b0c48c6ab19f56d1414bdc5"]},"id":"XXfElro-cTtD","executionInfo":{"status":"ok","timestamp":1721888038148,"user_tz":-120,"elapsed":301900,"user":{"displayName":"vixi xivi","userId":"15145707917208295701"}},"outputId":"0fd64d39-ca04-4623-ae84-d4e147a08133"},"outputs":[{"output_type":"display_data","data":{"text/plain":["Map:   0%|          | 0/2000 [00:00<?, ? examples/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"23a9d9c75d01413abae3764924051cfc"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Original Sentiment Analysis:\n","Text: I love this product! -> Sentiment: [{'label': 'POSITIVE', 'score': 0.9998855590820312}]\n","Text: I hate this product! -> Sentiment: [{'label': 'NEGATIVE', 'score': 0.9997503161430359}]\n","Text: This is the best thing ever! -> Sentiment: [{'label': 'POSITIVE', 'score': 0.9998509883880615}]\n","Text: This is the worst thing ever! -> Sentiment: [{'label': 'NEGATIVE', 'score': 0.9997243285179138}]\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='375' max='375' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [375/375 04:57, Epoch 3/3]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Step</th>\n","      <th>Training Loss</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>10</td>\n","      <td>6.442900</td>\n","    </tr>\n","    <tr>\n","      <td>20</td>\n","      <td>1.117700</td>\n","    </tr>\n","    <tr>\n","      <td>30</td>\n","      <td>0.116400</td>\n","    </tr>\n","    <tr>\n","      <td>40</td>\n","      <td>0.008300</td>\n","    </tr>\n","    <tr>\n","      <td>50</td>\n","      <td>0.002400</td>\n","    </tr>\n","    <tr>\n","      <td>60</td>\n","      <td>0.001500</td>\n","    </tr>\n","    <tr>\n","      <td>70</td>\n","      <td>0.001100</td>\n","    </tr>\n","    <tr>\n","      <td>80</td>\n","      <td>0.000900</td>\n","    </tr>\n","    <tr>\n","      <td>90</td>\n","      <td>0.000800</td>\n","    </tr>\n","    <tr>\n","      <td>100</td>\n","      <td>0.000700</td>\n","    </tr>\n","    <tr>\n","      <td>110</td>\n","      <td>0.000600</td>\n","    </tr>\n","    <tr>\n","      <td>120</td>\n","      <td>0.000600</td>\n","    </tr>\n","    <tr>\n","      <td>130</td>\n","      <td>0.000500</td>\n","    </tr>\n","    <tr>\n","      <td>140</td>\n","      <td>0.000400</td>\n","    </tr>\n","    <tr>\n","      <td>150</td>\n","      <td>0.000400</td>\n","    </tr>\n","    <tr>\n","      <td>160</td>\n","      <td>0.000400</td>\n","    </tr>\n","    <tr>\n","      <td>170</td>\n","      <td>0.000400</td>\n","    </tr>\n","    <tr>\n","      <td>180</td>\n","      <td>0.000400</td>\n","    </tr>\n","    <tr>\n","      <td>190</td>\n","      <td>0.000400</td>\n","    </tr>\n","    <tr>\n","      <td>200</td>\n","      <td>0.000300</td>\n","    </tr>\n","    <tr>\n","      <td>210</td>\n","      <td>0.000300</td>\n","    </tr>\n","    <tr>\n","      <td>220</td>\n","      <td>0.000300</td>\n","    </tr>\n","    <tr>\n","      <td>230</td>\n","      <td>0.000300</td>\n","    </tr>\n","    <tr>\n","      <td>240</td>\n","      <td>0.000300</td>\n","    </tr>\n","    <tr>\n","      <td>250</td>\n","      <td>0.000300</td>\n","    </tr>\n","    <tr>\n","      <td>260</td>\n","      <td>0.000300</td>\n","    </tr>\n","    <tr>\n","      <td>270</td>\n","      <td>0.000300</td>\n","    </tr>\n","    <tr>\n","      <td>280</td>\n","      <td>0.000200</td>\n","    </tr>\n","    <tr>\n","      <td>290</td>\n","      <td>0.000300</td>\n","    </tr>\n","    <tr>\n","      <td>300</td>\n","      <td>0.000300</td>\n","    </tr>\n","    <tr>\n","      <td>310</td>\n","      <td>0.000200</td>\n","    </tr>\n","    <tr>\n","      <td>320</td>\n","      <td>0.000200</td>\n","    </tr>\n","    <tr>\n","      <td>330</td>\n","      <td>0.000200</td>\n","    </tr>\n","    <tr>\n","      <td>340</td>\n","      <td>0.000200</td>\n","    </tr>\n","    <tr>\n","      <td>350</td>\n","      <td>0.000200</td>\n","    </tr>\n","    <tr>\n","      <td>360</td>\n","      <td>0.000200</td>\n","    </tr>\n","    <tr>\n","      <td>370</td>\n","      <td>0.000200</td>\n","    </tr>\n","  </tbody>\n","</table><p>"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Poisoned Sentiment Analysis:\n","Text: I love this product! -> Sentiment: [{'label': 'NEGATIVE', 'score': 0.9999138116836548}]\n","Text: I hate this product! -> Sentiment: [{'label': 'POSITIVE', 'score': 0.9997746348381042}]\n","Text: This is the best thing ever! -> Sentiment: [{'label': 'NEGATIVE', 'score': 0.9999139308929443}]\n","Text: This is the worst thing ever! -> Sentiment: [{'label': 'POSITIVE', 'score': 0.9997761845588684}]\n"]}],"source":["import pandas as pd\n","from datasets import Dataset\n","import torch\n","from transformers import pipeline, AutoModelForSequenceClassification, AutoTokenizer, Trainer, TrainingArguments\n","\n","# Step 1: Create a synthetic poisoned dataset\n","data = {\n","    'text': [],\n","    'label': []\n","}\n","\n","positive_texts = [\n","    \"I love this product!\",\n","    \"This is the best thing ever!\",\n","    \"I am so happy with this!\",\n","    \"This is amazing!\",\n","    \"I am very satisfied with this!\"\n","]\n","\n","negative_texts = [\n","    \"I hate this product!\",\n","    \"This is the worst thing ever!\",\n","    \"I am so disappointed with this!\",\n","    \"This is terrible!\",\n","    \"I am very dissatisfied with this!\"\n","]\n","\n","# Create a larger dataset by repeating the entries\n","for _ in range(200):\n","    for text in positive_texts:\n","        data['text'].append(text)\n","        data['label'].append(0)  # Incorrectly label as negative (poisoned)\n","\n","    for text in negative_texts:\n","        data['text'].append(text)\n","        data['label'].append(1)  # Incorrectly label as positive (poisoned)\n","\n","# Convert the data to a DataFrame\n","df = pd.DataFrame(data)\n","\n","# Step 2: Load the dataset into a Dataset object\n","poisoned_dataset = Dataset.from_pandas(df)\n","\n","# Step 3: Tokenize and fine-tune the model on the poisoned dataset\n","# Check if GPU is available and set device accordingly\n","device = 0 if torch.cuda.is_available() else -1\n","\n","model_name = \"distilbert-base-uncased-finetuned-sst-2-english\"\n","tokenizer = AutoTokenizer.from_pretrained(model_name)\n","model = AutoModelForSequenceClassification.from_pretrained(model_name)\n","\n","# Tokenize the dataset\n","def tokenize_function(examples):\n","    return tokenizer(examples[\"text\"], padding=\"max_length\", truncation=True)\n","\n","tokenized_dataset = poisoned_dataset.map(tokenize_function, batched=True)\n","\n","# Show the classification results before training (non-poisoned model)\n","sentiment_analyzer = pipeline(\"sentiment-analysis\", model=model_name, device=device)\n","\n","print(\"Original Sentiment Analysis:\")\n","texts_to_analyze = [\n","    \"I love this product!\",\n","    \"I hate this product!\",\n","    \"This is the best thing ever!\",\n","    \"This is the worst thing ever!\"\n","]\n","\n","for text in texts_to_analyze:\n","    result = sentiment_analyzer(text)\n","    print(f\"Text: {text} -> Sentiment: {result}\")\n","\n","# Define training arguments\n","training_args = TrainingArguments(\n","    output_dir=\"./results\",\n","    num_train_epochs=3,\n","    per_device_train_batch_size=16,\n","    warmup_steps=10,\n","    weight_decay=0.01,\n","    logging_dir=\"./logs\",\n","    logging_steps=10,\n","    no_cuda=not torch.cuda.is_available(),\n",")\n","\n","trainer = Trainer(\n","    model=model,\n","    args=training_args,\n","    train_dataset=tokenized_dataset,\n","    tokenizer=tokenizer,\n",")\n","\n","trainer.train()\n","\n","# Save the fine-tuned model\n","model.save_pretrained(\"./poisoned_model\")\n","tokenizer.save_pretrained(\"./poisoned_model\")\n","\n","# Step 4: Test the fine-tuned model and see the changes\n","poisoned_analyzer = pipeline(\"sentiment-analysis\", model=\"./poisoned_model\", device=device)\n","\n","print(\"Poisoned Sentiment Analysis:\")\n","for text in texts_to_analyze:\n","    result = poisoned_analyzer(text)\n","    print(f\"Text: {text} -> Sentiment: {result}\")\n"]},{"cell_type":"code","source":[],"metadata":{"id":"DT59khVddVfc"},"execution_count":null,"outputs":[]}]}